---
title: Zen
description: Lista selecionada de modelos fornecidos pelo opencode.
---

import config from "../../../../config.mjs"
export const console = config.console
export const email = `mailto:${config.email}`

O OpenCode Zen é uma lista de modelos testados e verificados fornecidos pela equipe do opencode.

:::note
O OpenCode Zen está atualmente em beta.
:::

O Zen funciona como qualquer outro provedor no opencode. Você faz login no OpenCode Zen e obtém sua chave de API. É **completamente opcional** e você não precisa usá-lo para utilizar o opencode.

---

## Contexto

Existe um grande número de modelos disponíveis, mas apenas alguns desses modelos funcionam bem como agentes de codificação. Além disso, a maioria dos provedores é configurada de maneira muito diferente; portanto, você obtém desempenhos e qualidades muito diferentes.

:::tip
Testamos um grupo selecionado de modelos e provedores que funcionam bem com o opencode.
:::

Portanto, se você estiver usando um modelo através de algo como OpenRouter, você nunca pode ter certeza se está obtendo a melhor versão do modelo que deseja.

Para resolver isso, fizemos algumas coisas:

1. Testamos um grupo selecionado de modelos e conversamos com suas equipes sobre como executá-los da melhor forma.
2. Trabalhamos com alguns provedores para garantir que esses modelos estivessem sendo servidos corretamente.
3. Finalmente, realizamos benchmarks da combinação modelo/provedor e elaboramos uma lista que nos sentimos bem em recomendar.

O OpenCode Zen é um gateway de IA que lhe dá acesso a esses modelos.

---

## Como funciona

O OpenCode Zen funciona como qualquer outro provedor no opencode.

1. Você faz login no **<a href={console}>OpenCode Zen</a>**, adiciona seus dados de cobrança e copia sua chave de API.
2. Você executa o comando `/connect` no TUI, seleciona OpenCode Zen e cola sua chave de API.
3. Execute `/models` no TUI para ver a lista de modelos que recomendamos.

Você é cobrado por solicitação e pode adicionar créditos à sua conta.

---

## Endpoints

Você também pode acessar nossos modelos através dos seguintes endpoints da API.

| Modelo             | ID do Modelo       | Endpoint                                           | Pacote AI SDK               |
| ------------------ | ------------------ | -------------------------------------------------- | --------------------------- |
| GPT 5.2            | gpt-5.2            | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.2 Codex      | gpt-5.2-codex      | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.1            | gpt-5.1            | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.1 Codex      | gpt-5.1-codex      | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.1 Codex Max  | gpt-5.1-codex-max  | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.1 Codex Mini | gpt-5.1-codex-mini | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5              | gpt-5              | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5 Codex        | gpt-5-codex        | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5 Nano         | gpt-5-nano         | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| Claude Sonnet 4.5  | claude-sonnet-4-5  | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Sonnet 4    | claude-sonnet-4    | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Haiku 4.5   | claude-haiku-4-5   | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Haiku 3.5   | claude-3-5-haiku   | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Opus 4.6    | claude-opus-4-6    | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Opus 4.5    | claude-opus-4-5    | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Opus 4.1    | claude-opus-4-1    | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Gemini 3 Pro       | gemini-3-pro       | `https://opencode.ai/zen/v1/models/gemini-3-pro`   | `@ai-sdk/google`            |
| Gemini 3 Flash     | gemini-3-flash     | `https://opencode.ai/zen/v1/models/gemini-3-flash` | `@ai-sdk/google`            |
| MiniMax M2.1       | minimax-m2.1       | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| MiniMax M2.1 Free  | minimax-m2.1-free  | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| GLM 4.7            | glm-4.7            | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| GLM 4.7 Free       | glm-4.7-free       | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| GLM 4.6            | glm-4.6            | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Kimi K2.5          | kimi-k2.5          | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Kimi K2.5 Free     | kimi-k2.5-free     | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Kimi K2 Thinking   | kimi-k2-thinking   | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Kimi K2            | kimi-k2            | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Qwen3 Coder 480B   | qwen3-coder        | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Big Pickle         | big-pickle         | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |

O [id do modelo](/docs/config/#models) na sua configuração do opencode usa o formato `opencode/<model-id>`. Por exemplo, para GPT 5.2 Codex, você usaria `opencode/gpt-5.2-codex` na sua configuração.

---

### Modelos

Você pode buscar a lista completa de modelos disponíveis e seus metadados em:

```
https://opencode.ai/zen/v1/models
```

---

## Preços

Nós suportamos um modelo de pagamento conforme o uso. Abaixo estão os preços **por 1M de tokens**.

| Modelo                            | Entrada | Saída  | Leitura em Cache | Escrita em Cache |
| --------------------------------- | ------- | ------ | ---------------- | ---------------- |
| Big Pickle                        | Grátis  | Grátis | Grátis           | -                |
| MiniMax M2.1 Free                 | Grátis  | Grátis | Grátis           | -                |
| MiniMax M2.1                      | $0.30   | $1.20  | $0.10            | -                |
| GLM 4.7 Free                      | Grátis  | Grátis | Grátis           | -                |
| GLM 4.7                           | $0.60   | $2.20  | $0.10            | -                |
| GLM 4.6                           | $0.60   | $2.20  | $0.10            | -                |
| Kimi K2.5 Free                    | Grátis  | Grátis | Grátis           | -                |
| Kimi K2.5                         | $0.60   | $3.00  | $0.08            | -                |
| Kimi K2 Thinking                  | $0.40   | $2.50  | -                | -                |
| Kimi K2                           | $0.40   | $2.50  | -                | -                |
| Qwen3 Coder 480B                  | $0.45   | $1.50  | -                | -                |
| Claude Sonnet 4.5 (≤ 200K tokens) | $3.00   | $15.00 | $0.30            | $3.75            |
| Claude Sonnet 4.5 (> 200K tokens) | $6.00   | $22.50 | $0.60            | $7.50            |
| Claude Sonnet 4 (≤ 200K tokens)   | $3.00   | $15.00 | $0.30            | $3.75            |
| Claude Sonnet 4 (> 200K tokens)   | $6.00   | $22.50 | $0.60            | $7.50            |
| Claude Haiku 4.5                  | $1.00   | $5.00  | $0.10            | $1.25            |
| Claude Haiku 3.5                  | $0.80   | $4.00  | $0.08            | $1.00            |
| Claude Opus 4.6 (≤ 200K tokens)   | $5.00   | $25.00 | $0.50            | $6.25            |
| Claude Opus 4.6 (> 200K tokens)   | $10.00  | $37.50 | $1.00            | $12.50           |
| Claude Opus 4.5                   | $5.00   | $25.00 | $0.50            | $6.25            |
| Claude Opus 4.1                   | $15.00  | $75.00 | $1.50            | $18.75           |
| Gemini 3 Pro (≤ 200K tokens)      | $2.00   | $12.00 | $0.20            | -                |
| Gemini 3 Pro (> 200K tokens)      | $4.00   | $18.00 | $0.40            | -                |
| Gemini 3 Flash                    | $0.50   | $3.00  | $0.05            | -                |
| GPT 5.2                           | $1.75   | $14.00 | $0.175           | -                |
| GPT 5.2 Codex                     | $1.75   | $14.00 | $0.175           | -                |
| GPT 5.1                           | $1.07   | $8.50  | $0.107           | -                |
| GPT 5.1 Codex                     | $1.07   | $8.50  | $0.107           | -                |
| GPT 5.1 Codex Max                 | $1.25   | $10.00 | $0.125           | -                |
| GPT 5.1 Codex Mini                | $0.25   | $2.00  | $0.025           | -                |
| GPT 5                             | $1.07   | $8.50  | $0.107           | -                |
| GPT 5 Codex                       | $1.07   | $8.50  | $0.107           | -                |
| GPT 5 Nano                        | Grátis  | Grátis | Grátis           | -                |

Você pode notar _Claude Haiku 3.5_ em seu histórico de uso. Este é um [modelo de baixo custo](/docs/config/#models) que é usado para gerar os títulos de suas sessões.

:::note
As taxas de cartão de crédito são repassadas ao custo (4,4% + $0,30 por transação); não cobramos nada além disso.
:::

Os modelos gratuitos:

- GLM 4.7 Free está disponível no opencode por tempo limitado. A equipe está usando esse tempo para coletar feedback e melhorar o modelo.
- Kimi K2.5 Free está disponível no opencode por tempo limitado. A equipe está usando esse tempo para coletar feedback e melhorar o modelo.
- MiniMax M2.1 Free está disponível no opencode por tempo limitado. A equipe está usando esse tempo para coletar feedback e melhorar o modelo.
- Big Pickle é um modelo oculto que está gratuito no opencode por tempo limitado. A equipe está usando esse tempo para coletar feedback e melhorar o modelo.

<a href={email}>Entre em contato conosco</a> se você tiver alguma dúvida.

---

### Recarga automática

Se seu saldo cair abaixo de $5, o Zen recarregará automaticamente $20.

Você pode alterar o valor da recarga automática. Você também pode desativar a recarga automática completamente.

---

### Limites mensais

Você também pode definir um limite de uso mensal para todo o espaço de trabalho e para cada membro de sua equipe.

Por exemplo, digamos que você defina um limite de uso mensal de $20, o Zen não usará mais de $20 em um mês. Mas se você tiver a recarga automática ativada, o Zen pode acabar cobrando mais de $20 se seu saldo cair abaixo de $5.

---

## Privacidade

Todos os nossos modelos estão hospedados nos EUA. Nossos provedores seguem uma política de zero retenção e não usam seus dados para treinamento de modelos, com as seguintes exceções:

- Big Pickle: Durante seu período gratuito, os dados coletados podem ser usados para melhorar o modelo.
- GLM 4.7 Free: Durante seu período gratuito, os dados coletados podem ser usados para melhorar o modelo.
- Kimi K2.5 Free: Durante seu período gratuito, os dados coletados podem ser usados para melhorar o modelo.
- MiniMax M2.1 Free: Durante seu período gratuito, os dados coletados podem ser usados para melhorar o modelo.
- APIs da OpenAI: As solicitações são retidas por 30 dias de acordo com as [Políticas de Dados da OpenAI](https://platform.openai.com/docs/guides/your-data).
- APIs da Anthropic: As solicitações são retidas por 30 dias de acordo com as [Políticas de Dados da Anthropic](https://docs.anthropic.com/en/docs/claude-code/data-usage).

---

## Para Equipes

O Zen também funciona muito bem para equipes. Você pode convidar colegas de equipe, atribuir funções, selecionar os modelos que sua equipe usa e muito mais.

:::note
Os espaços de trabalho estão atualmente gratuitos para equipes como parte do beta.
:::

Gerenciar seu espaço de trabalho é atualmente gratuito para equipes como parte do beta. Em breve, compartilharemos mais detalhes sobre os preços.

---

### Funções

Você pode convidar colegas de equipe para seu espaço de trabalho e atribuir funções:

- **Admin**: Gerenciar modelos, membros, chaves de API e cobrança
- **Membro**: Gerenciar apenas suas próprias chaves de API

Os administradores também podem definir limites de gastos mensais para cada membro para manter os custos sob controle.

---

### Acesso ao modelo

Os administradores podem habilitar ou desabilitar modelos específicos para o espaço de trabalho. Solicitações feitas a um modelo desabilitado retornarão um erro.

Isso é útil para casos em que você deseja desabilitar o uso de um modelo que coleta dados.

---

### Traga sua própria chave

Você pode usar suas próprias chaves de API da OpenAI ou Anthropic enquanto ainda acessa outros modelos no Zen.

Quando você usa suas próprias chaves, os tokens são cobrados diretamente pelo provedor, não pelo Zen.

Por exemplo, sua organização pode já ter uma chave para OpenAI ou Anthropic e você deseja usar essa em vez da que o Zen fornece.

---

## Objetivos

Criamos o OpenCode Zen para:

1. **Benchmark** os melhores modelos/provedores para agentes de codificação.
2. Ter acesso às opções de **mais alta qualidade** e não degradar o desempenho ou redirecionar para provedores mais baratos.
3. Repassar quaisquer **reduções de preço** vendendo ao custo; assim, a única margem é para cobrir nossas taxas de processamento.
4. Não ter **vinculação** permitindo que você o use com qualquer outro agente de codificação. E sempre permitir que você use qualquer outro provedor com o opencode também.
