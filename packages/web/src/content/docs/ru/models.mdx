---
title: Модели
description: Настройка поставщика и модели LLM.
---

opencode использует [AI SDK](https://ai-sdk.dev/) и [Models.dev](https://models.dev) для поддержки **более 75 поставщиков LLM** и поддерживает запуск локальных моделей.

---

## Провайдеры

Большинство популярных провайдеров предварительно загружены по умолчанию. Если вы добавили учетные данные для поставщика с помощью команды `/connect`, они будут доступны при запуске opencode.

Узнайте больше о [providers](/docs/providers).

---

## Выберите модель

После того, как вы настроили своего провайдера, вы можете выбрать нужную модель, введя:

```bash frame="none"
/models
```

---

## Рекомендуемые модели

Моделей очень много, новые выходят каждую неделю.

:::tip
Рассмотрите возможность использования одной из моделей, которые мы рекомендуем.
:::

Однако лишь немногие из них хороши как в генерации кода, так и в вызове инструментов.

Вот несколько моделей, которые хорошо работают с opencode (в произвольном порядке). (Это не исчерпывающий список и не обязательно актуальный):

- GPT 5.2
- Кодекс GPT 5.1
- Claude Opus 4.5
- Claude Sonnet 4.5
- MiniMax M2.1
- Gemini 3 Pro

---

## Установить значение по умолчанию

Чтобы установить одну из них в качестве модели по умолчанию, вы можете установить ключ `model` в вашем
Конфигурация opencode.

```json title="opencode.json" {3}
{
  "$schema": "https://opencode.ai/config.json",
  "model": "lmstudio/google/gemma-3n-e4b"
}
```

Здесь полный идентификатор `provider_id/model_id`. Например, если вы используете [OpenCode Zen](/docs/zen), вы должны использовать `opencode/gpt-5.1-codex` для кодекса GPT 5.1.

Если вы настроили [пользовательский поставщик](/docs/providers#custom), `provider_id` — это ключ из части `provider` вашей конфигурации, а `model_id` — это ключ из `provider.models`.

---

## Настройка моделей

Вы можете глобально настроить параметры модели через файл config.

```jsonc title="opencode.jsonc" {7-12,19-24}
{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "openai": {
      "models": {
        "gpt-5": {
          "options": {
            "reasoningEffort": "high",
            "textVerbosity": "low",
            "reasoningSummary": "auto",
            "include": ["reasoning.encrypted_content"],
          },
        },
      },
    },
    "anthropic": {
      "models": {
        "claude-sonnet-4-5-20250929": {
          "options": {
            "thinking": {
              "type": "enabled",
              "budgetTokens": 16000,
            },
          },
        },
      },
    },
  },
}
```

Здесь мы настраиваем глобальные параметры для двух встроенных моделей: `gpt-5` при доступе через поставщика `openai` и `claude-sonnet-4-20250514` при доступе через поставщика `anthropic`.
Названия встроенных поставщиков и моделей можно найти на сайте [Models.dev](https://models.dev).

Вы также можете настроить эти параметры для любых используемых вами агентов. Конфигурация агента переопределяет любые глобальные параметры здесь. [Подробнее](/docs/agents/#additional).

Вы также можете определить собственные варианты, расширяющие встроенные. Варианты позволяют настраивать разные параметры для одной и той же модели без создания повторяющихся записей:

```jsonc title="opencode.jsonc" {6-21}
{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "opencode": {
      "models": {
        "gpt-5": {
          "variants": {
            "high": {
              "reasoningEffort": "high",
              "textVerbosity": "low",
              "reasoningSummary": "auto",
            },
            "low": {
              "reasoningEffort": "low",
              "textVerbosity": "low",
              "reasoningSummary": "auto",
            },
          },
        },
      },
    },
  },
}
```

---

## Варианты

Многие модели поддерживают несколько вариантов с разными конфигурациями. opencode поставляется со встроенными вариантами по умолчанию для популярных провайдеров.

### Встроенные варианты

opencode поставляется с вариантами по умолчанию для многих провайдеров:

**Anthropic**:

- `high` — Бюджет рассуждений: высокий (по умолчанию)
- `max` — Максимальный бюджет рассуждений

**OpenAI**:

Зависит от модели, но примерно:

- `none` — Без рассуждений.
- `minimal` — Минимальные усилия для рассуждений
- `low` — Низкие усилия для рассуждений.
- `medium` — Средние усилия для рассуждений.
- `high` — Высокие усилия для рассуждений.
- `xhigh` — Сверхвысокие усилия для рассуждений.

**Google**:

- `low` – меньший бюджет усилий/токенов.
- `high` — более высокий бюджет усилий/токенов

:::tip
Этот список не является исчерпывающим. Многие другие провайдеры также имеют встроенные настройки по умолчанию.
:::

### Пользовательские варианты

Вы можете переопределить существующие варианты или добавить свои собственные:

```jsonc title="opencode.jsonc" {7-18}
{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
    "openai": {
      "models": {
        "gpt-5": {
          "variants": {
            "thinking": {
              "reasoningEffort": "high",
              "textVerbosity": "low",
            },
            "fast": {
              "disabled": true,
            },
          },
        },
      },
    },
  },
}
```

### Переключение вариантов

Используйте сочетание клавиш `variant_cycle` для быстрого переключения между вариантами. [Подробнее ](/docs/keybinds).

---

## Загрузка моделей

Когда opencode запускается, он проверяет модели в следующем порядке приоритета:

1. CLI-флаг `--model` или `-m`. Формат тот же, что и в файле конфигурации: `provider_id/model_id`.

2. Список моделей в конфигурации opencode.

   ```json title="opencode.json"
   {
     "$schema": "https://opencode.ai/config.json",
     "model": "anthropic/claude-sonnet-4-20250514"
   }
   ```

   Здесь используется формат `provider/model`.

3. Последняя использованная модель.

4. Первая модель, использующая внутренний приоритет.
