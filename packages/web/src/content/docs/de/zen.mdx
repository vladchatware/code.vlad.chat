---
title: Zen
description: Kuratierte Modellliste direkt von OpenCode.
---

import config from "../../../../config.mjs"
export const console = config.console
export const email = `mailto:${config.email}`

OpenCode Zen ist eine vom OpenCode-Team getestete und verifizierte Modellliste.

:::note
OpenCode Zen befindet sich aktuell in der Beta.
:::

Zen funktioniert wie jeder andere Provider in OpenCode.
Du meldest dich bei OpenCode Zen an, holst dir deinen API-Key und nutzt ihn optional.

---

## Hintergrund

Es gibt sehr viele Modelle, aber nur ein Teil davon eignet sich wirklich gut als Coding-Agent.
Ausserdem konfigurieren Provider Modelle sehr unterschiedlich, was die Qualitaet stark beeinflusst.

:::tip
Wir haben eine Auswahl aus Modellen und Providern getestet, die gut mit OpenCode funktionieren.
:::

Wenn du Modelle ueber Gateways wie OpenRouter nutzt, ist oft unklar, ob du die beste Ausfuehrung eines Modells bekommst.

Um das zu verbessern, haben wir:

1. Eine Auswahl an Modellen getestet und mit den Teams ueber optimale Laufzeit-Setups gesprochen
2. Mit Providern zusammengearbeitet, damit diese Modelle korrekt ausgeliefert werden
3. Modell/Provider-Kombinationen gebenchmarkt und eine empfehlenswerte Liste erstellt

OpenCode Zen ist ein AI-Gateway, das dir Zugriff auf genau diese Modelle gibt.

---

## Funktionsweise

OpenCode Zen funktioniert wie jeder andere Provider in OpenCode.

1. Melde dich bei **<a href={console}>OpenCode Zen</a>** an, hinterlege Zahlungsdaten und kopiere deinen API-Key.
2. Fuehre in der TUI `/connect` aus, waehle OpenCode Zen und fuege den API-Key ein.
3. Starte `/models` in der TUI, um empfohlene Modelle zu sehen.

Abgerechnet wird pro Anfrage, Guthaben kannst du jederzeit aufladen.

---

## Endpunkte

Du kannst unsere Modelle auch ueber die folgenden API-Endpunkte aufrufen.

| Model              | Model ID           | Endpoint                                           | AI SDK Package              |
| ------------------ | ------------------ | -------------------------------------------------- | --------------------------- |
| GPT 5.2            | gpt-5.2            | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.2 Codex      | gpt-5.2-codex      | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.1            | gpt-5.1            | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.1 Codex      | gpt-5.1-codex      | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.1 Codex Max  | gpt-5.1-codex-max  | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5.1 Codex Mini | gpt-5.1-codex-mini | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5              | gpt-5              | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5 Codex        | gpt-5-codex        | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| GPT 5 Nano         | gpt-5-nano         | `https://opencode.ai/zen/v1/responses`             | `@ai-sdk/openai`            |
| Claude Sonnet 4.5  | claude-sonnet-4-5  | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Sonnet 4    | claude-sonnet-4    | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Haiku 4.5   | claude-haiku-4-5   | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Haiku 3.5   | claude-3-5-haiku   | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Opus 4.6    | claude-opus-4-6    | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Opus 4.5    | claude-opus-4-5    | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Claude Opus 4.1    | claude-opus-4-1    | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| Gemini 3 Pro       | gemini-3-pro       | `https://opencode.ai/zen/v1/models/gemini-3-pro`   | `@ai-sdk/google`            |
| Gemini 3 Flash     | gemini-3-flash     | `https://opencode.ai/zen/v1/models/gemini-3-flash` | `@ai-sdk/google`            |
| MiniMax M2.1       | minimax-m2.1       | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| MiniMax M2.1 Free  | minimax-m2.1-free  | `https://opencode.ai/zen/v1/messages`              | `@ai-sdk/anthropic`         |
| GLM 4.7            | glm-4.7            | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| GLM 4.7 Free       | glm-4.7-free       | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| GLM 4.6            | glm-4.6            | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Kimi K2.5          | kimi-k2.5          | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Kimi K2.5 Free     | kimi-k2.5-free     | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Kimi K2 Thinking   | kimi-k2-thinking   | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Kimi K2            | kimi-k2            | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Qwen3 Coder 480B   | qwen3-coder        | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |
| Big Pickle         | big-pickle         | `https://opencode.ai/zen/v1/chat/completions`      | `@ai-sdk/openai-compatible` |

Die [Model-ID](/docs/config/#models) in deiner OpenCode-Konfiguration hat das Format `opencode/<model-id>`.
Fuer GPT 5.2 Codex verwendest du zum Beispiel `opencode/gpt-5.2-codex`.

---

### Models

Die komplette Liste verfuegbarer Modelle inklusive Metadaten findest du unter:

```
https://opencode.ai/zen/v1/models
```

---

## Preisgestaltung

Wir nutzen ein Pay-as-you-go-Modell.
Unten siehst du die Preise **pro 1 Mio. Tokens**.

| Model                             | Input  | Output | Cached Read | Cached Write |
| --------------------------------- | ------ | ------ | ----------- | ------------ |
| Big Pickle                        | Free   | Free   | Free        | -            |
| MiniMax M2.1 Free                 | Free   | Free   | Free        | -            |
| MiniMax M2.1                      | $0.30  | $1.20  | $0.10       | -            |
| GLM 4.7 Free                      | Free   | Free   | Free        | -            |
| GLM 4.7                           | $0.60  | $2.20  | $0.10       | -            |
| GLM 4.6                           | $0.60  | $2.20  | $0.10       | -            |
| Kimi K2.5 Free                    | Free   | Free   | Free        | -            |
| Kimi K2.5                         | $0.60  | $3.00  | $0.08       | -            |
| Kimi K2 Thinking                  | $0.40  | $2.50  | -           | -            |
| Kimi K2                           | $0.40  | $2.50  | -           | -            |
| Qwen3 Coder 480B                  | $0.45  | $1.50  | -           | -            |
| Claude Sonnet 4.5 (≤ 200K tokens) | $3.00  | $15.00 | $0.30       | $3.75        |
| Claude Sonnet 4.5 (> 200K tokens) | $6.00  | $22.50 | $0.60       | $7.50        |
| Claude Sonnet 4 (≤ 200K tokens)   | $3.00  | $15.00 | $0.30       | $3.75        |
| Claude Sonnet 4 (> 200K tokens)   | $6.00  | $22.50 | $0.60       | $7.50        |
| Claude Haiku 4.5                  | $1.00  | $5.00  | $0.10       | $1.25        |
| Claude Haiku 3.5                  | $0.80  | $4.00  | $0.08       | $1.00        |
| Claude Opus 4.6 (≤ 200K tokens)   | $5.00  | $25.00 | $0.50       | $6.25        |
| Claude Opus 4.6 (> 200K tokens)   | $10.00 | $37.50 | $1.00       | $12.50       |
| Claude Opus 4.5                   | $5.00  | $25.00 | $0.50       | $6.25        |
| Claude Opus 4.1                   | $15.00 | $75.00 | $1.50       | $18.75       |
| Gemini 3 Pro (≤ 200K tokens)      | $2.00  | $12.00 | $0.20       | -            |
| Gemini 3 Pro (> 200K tokens)      | $4.00  | $18.00 | $0.40       | -            |
| Gemini 3 Flash                    | $0.50  | $3.00  | $0.05       | -            |
| GPT 5.2                           | $1.75  | $14.00 | $0.175      | -            |
| GPT 5.2 Codex                     | $1.75  | $14.00 | $0.175      | -            |
| GPT 5.1                           | $1.07  | $8.50  | $0.107      | -            |
| GPT 5.1 Codex                     | $1.07  | $8.50  | $0.107      | -            |
| GPT 5.1 Codex Max                 | $1.25  | $10.00 | $0.125      | -            |
| GPT 5.1 Codex Mini                | $0.25  | $2.00  | $0.025      | -            |
| GPT 5                             | $1.07  | $8.50  | $0.107      | -            |
| GPT 5 Codex                       | $1.07  | $8.50  | $0.107      | -            |
| GPT 5 Nano                        | Free   | Free   | Free        | -            |

In deinem Verlauf siehst du eventuell _Claude Haiku 3.5_.
Das ist ein [guenstiges Modell](/docs/config/#models), das fuer Session-Titel verwendet wird.

:::note
Kreditkartengebuehren geben wir zum Selbstkostenpreis weiter (4,4 % + $0.30 pro Transaktion), ohne Aufschlag.
:::

Die kostenlosen Modelle:

- GLM 4.7 Free ist fuer begrenzte Zeit verfuegbar, um Feedback zu sammeln und das Modell zu verbessern.
- Kimi K2.5 Free ist fuer begrenzte Zeit verfuegbar, um Feedback zu sammeln und das Modell zu verbessern.
- MiniMax M2.1 Free ist fuer begrenzte Zeit verfuegbar, um Feedback zu sammeln und das Modell zu verbessern.
- Big Pickle ist ein Stealth-Modell und ebenfalls zeitlich begrenzt kostenlos verfuegbar.

Wenn du Fragen hast, <a href={email}>kontaktiere uns</a>.

---

### Auto-reload

Wenn dein Guthaben unter $5 faellt, laedt Zen automatisch $20 nach.

Du kannst den Betrag anpassen oder Auto-Reload komplett deaktivieren.

---

### Monatslimits

Du kannst monatliche Limits fuer den gesamten Workspace und pro Teammitglied festlegen.

Wenn du z. B. ein Monatslimit von $20 setzt, verbraucht Zen nicht mehr als $20 pro Monat.
Mit aktiviertem Auto-Reload kann die Abrechnung dennoch darueber liegen, falls das Guthaben unter $5 sinkt.

---

## Datenschutz

Alle Modelle werden in den USA gehostet.
Unsere Provider arbeiten grundsaetzlich mit Zero-Retention und nutzen deine Daten nicht zum Training, mit folgenden Ausnahmen:

- Big Pickle: During its free period, collected data may be used to improve the model.
- GLM 4.7 Free: During its free period, collected data may be used to improve the model.
- Kimi K2.5 Free: During its free period, collected data may be used to improve the model.
- MiniMax M2.1 Free: During its free period, collected data may be used to improve the model.
- OpenAI APIs: Requests are retained for 30 days in accordance with [OpenAI's Data Policies](https://platform.openai.com/docs/guides/your-data).
- Anthropic APIs: Requests are retained for 30 days in accordance with [Anthropic's Data Policies](https://docs.anthropic.com/en/docs/claude-code/data-usage).

---

## Für Teams

Zen eignet sich auch gut fuer Teams.
Du kannst Mitglieder einladen, Rollen vergeben und den Modellzugriff fuer dein Team steuern.

:::note
Workspaces sind fuer Teams waehrend der Beta derzeit kostenlos.
:::

Workspace-Verwaltung ist in der Beta kostenlos.
Details zur spaeteren Preisgestaltung folgen.

---

### Rollen

Du kannst Teammitglieder einladen und Rollen vergeben:

- **Admin**: Verwalten Modelle, Mitglieder, API-Keys und Abrechnung
- **Member**: Verwalten nur eigene API-Keys

Admins koennen zusaetzlich monatliche Ausgabenlimits pro Mitglied setzen.

---

### Modellzugriff

Admins koennen einzelne Modelle fuer den Workspace aktivieren oder deaktivieren.
Anfragen an deaktivierte Modelle liefern einen Fehler.

Das ist hilfreich, wenn bestimmte datenverarbeitende Modelle ausgeschlossen werden sollen.

---

### Eigenen Key mitbringen

Du kannst eigene OpenAI- oder Anthropic-API-Keys verwenden und trotzdem andere Zen-Modelle nutzen.

Bei eigenen Keys erfolgt die Token-Abrechnung direkt ueber den Provider, nicht ueber Zen.

For example, your organization might already have a key for OpenAI or Anthropic
and you want to use that instead of the one that Zen provides.

---

## Ziele

Wir haben OpenCode Zen entwickelt, um:

1. Die besten Modell/Provider-Kombinationen fuer Coding-Agenten zu **benchmarken**
2. Stets **hohe Qualitaet** ohne Downgrades oder versteckte Umleitungen auf billigere Provider zu liefern
3. **Preissenkungen** zum Selbstkostenpreis weiterzugeben, mit Aufschlag nur fuer Zahlungsgebuehren
4. **Kein Lock-in** zu erzwingen, damit du Zen mit anderen Coding-Agents und OpenCode weiter mit anderen Providern nutzen kannst
